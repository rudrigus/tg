%TCIDATA{LaTeXparent=0,0,relatorio.tex}
                      

\chapter{Desenvolvimento}\label{CapDesenvolvimento}

% Resumo opcional. Comentar se não usar.
% \resumodocapitulo{Resumo opcional.}

\section{Introdução}

O trabalho consistiu basicamente em duas etapas. Na primeira foi desenvolvido um algoritmo de processamento em um computador com software de alto nível de abstração, o Matlab, e na segunda foi feita a implementação em hardware do mesmo algoritmo utilizando um FPGA.

Inicialmente, o algoritmo em Matlab foi criado para fazer as medidas necessárias em apenas uma imagem, até que se percebeu que seria necessário usar média de imagens. Depois passaram a ser processados grandes grupos de imagens armazenadas.

O sistema em FPGA, escrito em VHDL, foi concebido para processar imagens à medida que são capturadas, em tempo real. As últimas etapas do algoritmo não foram implementadas no sistema em hardware como se desejava.

Infelizmente não foi possível obter dados reais com a câmera, pois não havia uma interface física entre o cabo de comunicação da câmera e o FPGA. Por esse motivo foi utilizada a memória da placa para fornecer dados ao processador de imagens desenvolvido.

\section{Arquitetura geral}

O sistema deverá fazer parte de um controlador em malha fechada, que espera-se que seja superior ao controle de malha aberta comumente utilizado em sistemas soldas automatizadas. Ou seja, o sinal de entrada deve ser o resultado da soma do sinal de referência, que será o trajeto definido na programação de um robô, e do sinal de controle, que será calculado por um computador.

Para que o sistema seja realimentado é necessário obter medidas da saída do sistema e, se possível, outros estados. O estado de saída no caso será obtido através de um algoritmo que irá processar fotos do processo e retornar valores numéricos relevantes à operação. Esta etapa é feita com o uso de uma câmera de alta taxa de captura de imagens, capaz de fotografar o arame e a poça de soldagem no instante em que há um curto circuito. O algoritmo processa as imagens e obtém valores numéricos de tamanho da poça, desvio e inclinação do arame.

% Finalmente, o algoritmo calcula e fornece um sinal de controle para corrigir o posicionamento da tocha de soldagem ou parâmetros como velocidade de alimentação do arame e corrente elétrica.

\pagebreak
\section{Implementação em Matlab} \label{section:implementacao-matlab}


O primeiro algoritmo foi desenvolvido para funcionamento de forma sequencial, pois seria implementado com o software Matlab. A sequência de operações foi definida de acordo com a descrição abaixo. As descrições entre parênteses indicam os parâmetros utilizados em testes que obtiveram bons resultados.

\subsection{Algoritmo Base}

O diagrama da figura \ref{fig:diagrama-algoritmo} demonstra a sequência de instruções criadas no Matlab para processar as imagens:


\begin{figure}[h!]
\centering
{\includegraphics[width=.46\textwidth]{./Figuras/diagrama-algoritmo.png}}
\caption{Diagrama do algoritmo utilizado}
\label{fig:diagrama-algoritmo}
\end{figure}

A sequência de passos pode ser lida com mais detalhes abaixo:

\begin{framed}
\begin{enumerate}
\item Limpar memória e fechar figuras
\item Carregar quantidadeImagens imagens (quantidadeImagens=3)
\item Criar imagem média das imagens carregadas -> I

\item Retirar pixels abaixo de threshold1 para retirar scanlines (threshold1 = 10)
\item Filtro de mediana em I para retirar ruído -> I2
\item Retirar pixels abaixo de threshold2  de I2 -> B (threshold2 = 40)

\item Encontrar topo e base do arame
\subitem  Criar vetor de soma do perfil horizontal de B -> somaHor
\subitem  Criar vetor de derivadas de somaHor -> derivadaHor
\subitem  Encontrar topo do arame
\subsubitem    Valor máximo de derivadaHor entre o topo da imagem e o provável meio do arame (meioVert = 125) -> posArameTopo
\subitem  Encontrar base do arame
\subsubitem    Valor mínimo de derivadaHor entre o meio do arame e o fim da imagem - posArameBase

\item Encontrar borda esquerda e direita da poça de soldagem
\subitem  Criar vetor de soma do perfil vertical de B -> somaVert
\subitem  Criar vetor de derivadas de somaVert -> derivadaVert
\subitem  Encontrar borda esquerda da poça
\subsubitem    Valor máximo de derivadaVert entre o começo e o meio da imagem -> limEsqPoca
\subitem  Encontrar borda direita da poça
\subsubitem    Valor mínimo de derivadaVert entre o meio e o final da imagem -> limDirPoca

\item Encontrar laterais do arame
\subitem  Criar vetor de derivadas de B na horizontal entre topo e base do arame -> derivadaArame
\subitem  Valores mínimos de derivadaArame -> vetor inicioArame
\subitem  Valores máximos de derivadaArame -> vetor fimArame
\subitem  Linearizar inicioArame e fimArame
\end{enumerate}
\end{framed}

Esses passos com os valores para os parâmetros definidos acima obtiveram bons resultados para uma grande quantidade de imagens (antigas). O algoritmo demonstrou certa robustez a ruídos, porém quando a imagem foge muito ao padrão esperado, o algoritmo fornece valores equivocados. Um exemplo é quando há uma grande gota de solda fora da área da poça. 
% Mencionar que deve ser usado um filtro de Kalman?

% mostrar exemplo

\subsection{Filtros}
\label{section:desenv-filtros}
A escolha dos filtros utilizados foi baseada nas características do processo e das próprias imagens, já conhecidas. Abaixo segue a sequência de filtro utilizados.

\begin{enumerate}
\item Média de imagens

Não é um filtro muito comumente utilizado, mas se provou útil neste trabalho. Observou-se em várias imagens objetos brilhosos que aparecem aleatoriamente, provavelmente respingos de solda e fagulhas. São ruídos muito grandes para serem retirados com filtros de janela. O interessante é que estes objetos não costumam estar presentes em mais de uma imagem. As características do processo favorecem o uso da média, pois as imagens as formas a serem identificadas mudam pouco de \textit{frame} a \textit{frame}.

A média de imagens reduz bastante este efeito e quanto maior o número de imagens utilizadas, menor o efeito de deste tipo de ruído. Em contrapartida, o uso de muitas imagens pode propagar o ruído durante muitas leituras, o que comprometeria a eficácia do processamento de sinais mais tarde. Portanto, deve-se escolher uma quantidade razoável de imagens a serem utilizadas na média. Durante as simulações observou-se que três a cinco imagens são o suficiente para atenuar consideravelmente estes ruídos.

\begin{figure}[h!]
\centering
\subfigure[\label{fig:media-imagens-3}]{
	\includegraphics[width=\textwidth]{./Figuras/ExImagemMedia3.jpg}}
\subfigure[\label{fig:media-imagens-5}]{
	{\includegraphics[width=\textwidth]{./Figuras/ExImagemMedia5.jpg}}}
\caption{Média de três imagens (a). Média de cinco imagens(b)}
\label{fig:media-imagens}
\end{figure}

\item Binarização

Esta binarização retira as \textit{scanlines} verticais que estão presentes em todas as imagens. Essas \textit{scanlines} são fruto do ruído de fundo da câmera CMOS e só se observam em regiões onde a luminosidade é mínima, ou seja 0/255. Na figura \ref{fig:detalhe-scanlines} pode-se ver que elas não continuam sobre regiões mais brilhosas. As \textit{scanlines} são pouco mais claras que o preto total (geralmente menor que 6/255), portanto é utilizado um filtro de binarização simples. Quase nenhuma informação útil é perdida neste passo. Pois a maior parte das informações úteis estão contidas em pixels com brilho médio a alto (acima de 40/255).

\begin{figure}[h!]
\hspace{1.5em}
\begin{minipage}[t]{.75\textwidth}
\vspace{0pt}
\centering
\includegraphics[width=\textwidth]{./Figuras/Img150-detalhe2.jpg}
\end{minipage}
\begin{minipage}[t]{.2\textwidth}
\small
\vspace{0pt}
\def\arraystretch{.9}
\setlength\tabcolsep{.015\textwidth}
\begin{tabular}{c c c c c c c c}
 6 &  5 &  3 &  0 &  6 &  5 &  3 &  0\\
 6 &  5 &  3 &  0 &  6 &  5 &  3 &  0\\
 7 &  5 &  3 &  0 &  6 &  5 &  3 &  0\\
 7 & 11 &  5 &  2 &  6 &  9 &  3 &  5\\
20 & 25 & 21 & 13 & 13 & 25 & 23 & 30\\
53 & 50 & 38 & 36 & 42 & 41 & 35 & 47\\
65 & 66 & 57 & 66 & 60 & 63 & 63 & 69\\
78 & 70 & 75 & 66 & 71 & 75 & 65 & 79\\

\end{tabular}
\end{minipage}\hfill
\caption{Detalhe de imagem e valores numéricos dos pixels}
\label{fig:detalhe-scanlines}
\end{figure}

A figura \ref{fig:detalhe-scanlines} demonstra um pedaço da imagem onde se podem ver as \textit{scanlines} e como a parte mais brilhosa não sofre este efeito. Ao lado os valores numéricos são mostrados. Concluiu-se que o valor de $threshold1 = 7$ para a retirada das scanlines era mais que suficiente, sem afetar informações úteis.

\item Gaussiana

Este filtro é de gaussiana com janela 3x3 para tirar pequenos ruídos. Também contribui para suavizar as bordas antes do próximo filtro.

\item Binarização

O segundo filtro de binarização tem o objetivo de retirar mais ruídos e acentuar as bordas da imagem. Usado depois do filtro de gaussiana tem-se a impressão de bordas mais definidas. Por exemplo, o perfil fica mais reto onde deveria haver uma reta. Ambos os filtros de binarização são parciais  e mantêm o brilho dos pixels com valor acima do $threshold2 = 40$ e abaixo do $threshold3 = 100$.

É importante ressaltar que a ordem de utilização dos filtros afeta o resultado final, por isso foi feita a primeira binarização antes do filtro de gaussiana para que as \textit{scanlines} não interferissem nas bordas com informações úteis.

\end{enumerate}

\subsection{Perfis Verticais e Horizontais}\label{section:desenv-matlab-perfis}

Uma das ferramentas essenciais neste trabalho foi o uso de perfis verticais e horizontais e suas derivadas. A escolha deste método levou em consideração algumas características particulares do processo em questão:

\begin{enumerate}
\item As imagens são em tons de cinza, portanto há apenas um valor numérico a ser lido em cada píxel;
\item O objeto de interesse nas imagens é bastante definido em relação ao fundo e é único;
\item Este método permite uma comparação relativamente precisa entre imagens seguidas.
\end{enumerate}

São gerados dois vetores de perfis, o $somaHor$ e o $somaVert$ e suas derivadas $derivadaHor$ e $derivadaVert$, respectivamente.

O vetor $somaHor$ representa a luminosidade somada em cada linha (horizontal) da imagem analisada. Analogamente O vetor $somaVert$ representa a luminosidade somada em cada coluna (vertical) da imagem analisada.

O vetor $derivadaHor$ representa as variações de luminosidade a cada linha (horizontal) da imagem e é utilizado para encontrar as coordenadas $Y$ do topo ($posArameTopo$) e da base ($posArameBase$) do eletrodo na imagem. Essas posições são encontradas nos máximos locais de $derivadaHor$. É possível perceber na figura \ref{fig:im-ex-perfil-hor} onde se encontram esses mínimos e máximos, além de uma perspectiva geral de $somaHor$.


% gerar imagens mostrando os perfis
%I = imread('/home/rudrigus/UNB/TG/Imagens/Capturas/1000 fps/Resultados Filtro Adaptativo/Img167.bmp');
%tamanho = size(I);
%Threshold1 = 7;
%Threshold2 = 40;
%Threshold3 = 100;
%% if filtrar==1
%%% Retirar scanlines
%a = I > Threshold1;
%%c = cast(a,'uint8');
%I = single(I).*a;
%%% Filtro de gaussiana
%H = fspecial('gaussian',3);
%I = imfilter(I,H,'replicate');
%% end
%B  = I > Threshold2;
%I2 = I.*B;
%ImagemTratada = min(I2,Threshold3);
%somaHor     = sum(ImagemTratada,2);
%derivadaHor = diff(somaHor);
%figure;image(ImagemTratada);colormap(gray(256));hold on;
%plot(somaHor(:,1,1)/(max(somaHor)/tamanho(2)),1:1:tamanho(1));
%plot(tamanho(2)/2 + derivadaHor(:,1)/(-min(derivadaHor)/tamanho(2)),1:1:th(1));
%plot(derivadaHor(:,1)/(max(derivadaHor)/tamanho(1)),1:1:th(1));
%
%somaVert     = sum(ImagemTratada,1);
%derivadaVert = diff(somaVert);
%figure;image(ImagemTratada);colormap(gray(256));hold on;
%plot(tamanho(1)-somaVert(1,:,1)/(max(somaVert)/tamanho(1)));
%plot(tamanho(1)/2-derivadaVert(1,:,1)/(-2*min(derivadaVert)/tamanho(1)));


\begin{figure}[h!]
\centering
{\includegraphics[width=\textwidth]{./Figuras/imagem+perfilHorizontal+derivada.jpg}}
\caption{Imagem com perfil horizontal(verde) e derivada do perfil(vermelho)}
\label{fig:im-ex-perfil-hor}
\end{figure}

O vetor $derivadaVert$ representa as variações de luminosidade a cada coluna (vertical) da imagem e é utilizado para encontrar as coordenadas $X$ das bordas esquerda ($limEsqPoca$) e direita ($limDirPoca$) da poça. Essas posições são encontradas nos máximos locais de $derivadaVert$. É possível perceber na figura \ref{fig:im-ex-perfil-vert} onde se encontram esses mínimos e máximos, além de uma perspectiva geral de $somaVert$.


\begin{figure}[h!]
\centering
{\includegraphics[width=\textwidth]{./Figuras/imagem+perfilVertical+derivada.jpg}}
\caption{Imagem com perfil vertical(verde) e derivada do perfil(vermelho)}
\label{fig:im-ex-perfil-vert}
\end{figure}


\subsection{Regressão Robusta}

Um dos passos do algoritmo é encontrar os pontos de interesse do eletrodo. Para simplificação dos cálculos considerou-se o perfil do eletrodo em cada imagem como um trapézio. Desta forma apenas são necessários encontrar quatro pontos para se determinar a posição, comprimento e desvio angular do eletrodo. Estes pontos são definidos pelas intersecções entre base e topo do eletrodo e suas laterais.

A princípio pensou-se em identificar apenas os pontos das laterais do eletrodo mais próximos ao topo e à base do mesmo para se definir esses pontos. Esta identificação seria pelo método dos perfis verticais (\ref{section:rev-perfis}). Contudo, verificou-se que é comum haverem objetos brilhosos sobre alguma parte do eletrodo e inclusive sobre parte de suas bordas. Também, a ponta (base) do eletrodo geralmente está deformada por conta da fusão do material neste ponto. Esses objetos ou deformações sobre os pontos desejados causam grandes erros de medição ao simplesmente se utilizar este método.

Portanto, decidiu-se que estes pontos deveriam ser encontrados de forma mais robusta. A primeira tentativa foi obter diversos pontos ao longo do arame e se fazer uma regressão linear de tais pontos com a função $polyfit$ do Matlab. Essas retas foram definidas como vetores de dois elementos que representam os coeficientes das equações de reta, armazenados em $ladoEsqArame$ e $ladoDirArame$. Com esses coeficientes, seriam calculadas as coordenadas no eixo $X$ onde as retas encontradas se cruzavam com as medidas $Y$ da base e topo do eletrodo.

A regressão linear comum reduziu alguns dos erros mas ainda não estava satisfatória. Portanto, foi utilizada uma regressão robusta em vez de uma de mínimos quadrados para se obter a equação da reta de cada lateral do eletrodo.

A função utilizada para essa tarefa foi a $robustfit$ do Matlab, com a configuração padrão "bisquare". Esta função retorna o mesmo formato de coeficientes da equação de reta que a função $polyfit$. Dessa forma, as coordenadas dos pontos de interesse são obtidos com o mesmo procedimento.

% gerar imagens 
%I0 = imread('/home/rudrigus/UNB/TG/Imagens/Capturas/1000 fps/Resultados Filtro Adaptativo/Img149.bmp');
% I1 = imread('/home/rudrigus/UNB/TG/Imagens/Capturas/1000 fps/Resultados Filtro Adaptativo/Img150.bmp');
% I2 = imread('/home/rudrigus/UNB/TG/Imagens/Capturas/1000 fps/Resultados Filtro Adaptativo/Img151.bmp');
% tamanho = size(I0);
% Im = zeros(tamanho(1),tamanho(2),3);
% Im(:,:,1) = I0;
% Im(:,:,2) = I1;
% Im(:,:,3) = I2;
% I = mean(Im,3);
% Threshold1 = 7;
% Threshold2 = 40;
% Threshold3 = 100;
% % if filtrar==1
% %% Retirar scanlines
% a = I > Threshold1;
% %c = cast(a,'uint8');
% I = single(I).*a;
% %% Filtro de gaussiana
% H = fspecial('gaussian',3);
% I = imfilter(I,H,'replicate');
% % end
% B  = I > Threshold2;
% I2 = I.*B;
% 
% ImagemTratada = min(I2,Threshold3);
% 
% %%
% % perfil horizontal, de cima para baixo
% somaHor     = sum(ImagemTratada,2);
% derivadaHor = diff(somaHor);
% 
% % limiares tamanhos uteis
% meioVert = floor(tamanho(1)/2);
% meioHor =  floor(tamanho(2)/2);
% 
% % limites verticais do arame
% [M,posArameTopo] = max(derivadaHor(1:1:meioVert-1));
% [M,posArameBase] = max(derivadaHor(meioVert:1:tamanho(1)-1));
% posArameBase     = posArameBase + meioVert;

% %%
% % limites horizontais do arame
% % perfil vertical, da esquerda para a direita
% somaVert     = sum(ImagemTratada,1);
% derivadaVert = diff(somaVert);
% 
% %%
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % Borda esquerda da poca
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% [M, limEsqPoca] = max(derivadaVert(1:1:meioHor));
% 
% %%
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % Borda direita da poca
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% [M, limDirPoca] = min(derivadaVert(meioHor:1:tamanho(2)-1));
% limDirPoca = limDirPoca + meioHor;
% 
% 
% 
% %%
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % Laterais do arame, inicioArame (esquerda) e fimArame (direita)
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% afastamento1 = floor(0.01*tamanho(1));
% afastamento2 = floor(0.01*tamanho(1));
% n = posArameBase - posArameTopo - afastamento1 - afastamento2; % Usar n valor menor (como n = 15) para diminuir processamento
% intervalo = 1;% correcao caso se diminua valor de n(posArameBase - posArameTopo - afastamento1 - afastamento2)/(n-1)
% inicioArame = zeros(n,1);
% fimArame = zeros(n,1);
% derivadaArame = zeros(n,tamanho(2)-1);
% for i = 1:1:n+1
%     derivadaArame(i,:) = diff(B(posArameTopo + afastamento1 + round(intervalo*(i-1)),:));
%     [M, inicioArame(i)] = min(derivadaArame(i,floor(meioHor/2):1:meioHor));
%     inicioArame(i) = inicioArame(i) + floor(meioHor/2);
%     [M, fimArame(i)] = max(derivadaArame(i,meioHor:1:tamanho(2)-1));
%     fimArame(i) = fimArame(i) + meioHor;
% end
% % X = size(posArameTopo+afastamento1:intervalo:posArameBase-afastamento2)
% % Y = size(inicioArame)
% 
% 
% % bordas com regressão comum
% 
% ladoEsqArame = robustfit(posArameTopo+afastamento1:intervalo:posArameBase-afastamento2,inicioArame,'ols');
% ladoDirArame = robustfit(posArameTopo+afastamento1:intervalo:posArameBase-afastamento2,fimArame,'ols');
% 
%   figure;image(I2);colormap(gray(256))
% %   title(j)
%   hold on;
%   %pontos encontrados
%   plot(inicioArame,[posArameTopo + afastamento1:1:posArameBase-afastamento2],'.g');
%   plot(fimArame,[posArameTopo + afastamento1:1:posArameBase-afastamento2],'.g');
%   %lados esquerdo e direito do arame
%   plot([posArameTopo*ladoEsqArame(2)+ladoEsqArame(1) posArameBase*ladoEsqArame(2)+ladoEsqArame(1)],[posArameTopo posArameBase],'r')
%   plot([posArameTopo*ladoDirArame(2)+ladoDirArame(1) posArameBase*ladoDirArame(2)+ladoDirArame(1)],[posArameTopo posArameBase],'r')
%   %topo e base do arame
%   plot(1:1:tamanho(2),ones(tamanho(2))*posArameTopo,'b');
%   plot(1:1:tamanho(2),ones(tamanho(2))*posArameBase,'b');
% 
%   
% % bordas com regressão robusta
% 
% ladoEsqArameRobusto = robustfit(posArameTopo+afastamento1:intervalo:posArameBase-afastamento2,inicioArame);
% ladoDirArameRobusto = robustfit(posArameTopo+afastamento1:intervalo:posArameBase-afastamento2,fimArame);
% 
%   figure;image(I2);colormap(gray(256))
% %   title(j)
%   hold on;
%   %pontos encontrados
%   plot(inicioArame,[posArameTopo + afastamento1:1:posArameBase-afastamento2],'.g');
%   plot(fimArame,[posArameTopo + afastamento1:1:posArameBase-afastamento2],'.g');
%   %lados esquerdo e direito do arame
%   plot([posArameTopo*ladoEsqArameRobusto(2)+ladoEsqArameRobusto(1) posArameBase*ladoEsqArameRobusto(2)+ladoEsqArameRobusto(1)],[posArameTopo posArameBase],'r')
%   plot([posArameTopo*ladoDirArameRobusto(2)+ladoDirArameRobusto(1) posArameBase*ladoDirArameRobusto(2)+ladoDirArameRobusto(1)],[posArameTopo posArameBase],'r')
%   %topo e base do arame
%   plot(1:1:tamanho(2),ones(tamanho(2))*posArameTopo,'b');
%   plot(1:1:tamanho(2),ones(tamanho(2))*posArameBase,'b');

\begin{figure}[h!]
\subfigure[\label{fig:regressao-linear}]{
	\centering
	\includegraphics[width=.5\textwidth]{./Figuras/imagem-regressao-quadrados.jpg}}
\subfigure[\label{fig:regressao-robusta}]{
	\centering
	\includegraphics[width=.5\textwidth]{./Figuras/imagem-regressao-robusta.jpg}}
\caption{Regressão por mínimos quadrados (a) versus regressão robusta (b)}
\label{fig:regressao-linear+robusta}
\end{figure}

A figura \ref{fig:regressao-linear} demonstra como a regressão por mínimos quadrados foi capaz de corrigir encontrar corretamente os pontos do eletrodo no lado direito mas falhou para o lado esquerdo. Já a figura \ref{fig:regressao-robusta} demonstra a vantagem da regressão robusta.

\subsection{Distorção de perspectiva}

A câmera deve ser posicionada obliquamente em relação à poça de soldagem não apenas por questões físicas mas também para que inclua tanto poça de soldagem quanto arame. Isso significa que os elementos (poça e arame) ficam em diagonal com o plano da imagem, o que causa uma distorção de perspectiva do que seria a imagem ideal para processamento. A posição da câmera que capturou as imagens utilizadas nesta parte do experimento pode ser vista na figura \ref{fig:posicao-camera-luciano}.

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{./Figuras/posicao-camera-luciano.png}
\caption{Posição da câmera \cite{luciano}}
\label{fig:posicao-camera-luciano}
\end{figure}

Dessa forma, a distorção de perspectiva da imagem deve ser conhecida para que seja possível obter valores corretos no processamento. Uma forma de obter essa informação seria por inserção de dados como ângulo, distância entre câmera e tocha, e distância focal da lente por um operador no sistema. Mas considerando que o sistema possa ser utilizado  com câmeras, atuadores e posicionamentos diferentes, inclusive com a possibilidade de alteração de alguma variável entre dois \textit{setups} diferentes, há a possibilidade de erros e aumento do tempo de \textit{setup}.

A princípio, desejava-se calcular a distorção de perspectiva e fazer os ajustes necessários durante o processamento das imagens do processo de solda. A ideia seria utilizar os cantos do eletrodo de solda (dois formados entre o topo do eletrodo e o bocal da tocha e dois entre a base do eletrodo e a poça de soldagem) para identificar os pontos necessários para este cálculo. No entanto, alguns fatos foram observados:

\begin{enumerate}
\item O eletrodo pode, em dado momento, estar em uma posição oblíqua à peça de soldagem.

Independente do motivo, à partir de imagens sabe-se que isso acontece no plano ortogonal à direção da soldagem. Presume-se que o mesmo ocorre também no plano que é paralelo à direção de soldagem e perpendicular à peça. Isso significa que o eletrodo pode estar mais à frente ou atrás do centro da tocha de solda, aproximando-se ou afastando-se da câmera. Ou seja, os pontos que deveriam ser conhecidos na base do eletrodo movem-se para locais desconhecidos, impossibilitando o cálculo correto da matriz de transformação.

\item O tamanho do eletrodo varia.

Fato também observado em imagens, tem o mesmo efeito que a variação de direção do eletrodo. A ponta do eletrodo está hora mais perto hora mais longe da peça de soldagem, mesmo quando em regime estável da soldagem. Isso também muda a posição de pontos que deveriam ser conhecidos.
\end{enumerate}


Devido aos motivos listados o sistema deve obter a matriz de transformação através de uma pré-calibração. Pensou-se em uma forma simples e rápida: esta pré calibração é feita com o processamento de uma imagem inicial e a matriz de transformação fica armazenada no sistema até que seja feito um novo \textit{setup}. A imagem deve conter o mínimo de quatro pontos conhecidos, como descrito em \ref{section:CalculoMatrizTransf} no espaço tridimensional para que seja possível calcular a matriz de transformação.

A pré calibração é feita utilizando-se um objeto quadrado de dimensões conhecidas no plano paralelo à peça que será soldada. Isso pode ser feito colocando-se uma pequena chapa metálica quadrada sobre o plano de soldagem. Apenas uma imagem é necessária para se obter a matriz de transformação, desde que o resto do ambiente contido na imagem seja bem controlado no momento da calibração. Os algoritmo gerado com Matlab para gerar a matriz de transformação se mostrou eficiente, mas pode apresentar erros caso haja na imagem cantos mais definidos que os cantos do quadrado.

O algoritmo da pré-calibração em Matlab é razoavelmente simples pois utiliza as funções prontas no software. Abaixo seguem os passos utilizados:

\begin{enumerate}
\item Filtragem da imagem

Basicamente são retirados os pixels abaixo de um threshold e depois passado um filtro de gaussiana para retirada de ruídos.

\item Detecção de cantos

A função ''corner'' do Matlab é chamada e utiliza o método de Harris (seção \ref{section:DeteccaoCanto}) para a detecção. Os cantos são ordenados descendentemente.

\item Cálculo da matriz de transformação

As coordenadas reais dos cantos são utilizadas em conjunto com as coordenadas obtidas na detecção do passo anterior para o cálculo. (seção \ref{section:CalculoMatrizTransf})

\item Transformação da imagem

Aqui o algoritmo apresenta a imagem transformada com a matriz de transformação.

\item Correção de valores calculados em etapas anteriores

As distâncias e posições encontradas anteriormente são corrigidas e sofrem menos influência da distorção.

\end{enumerate}

O interessante de se fazer a correção desta forma, é que também so torna possível estimar desvios do arame na direção do eixo de avanço. Considerando-se uma imagem corrigida após as distorção, observa-se o seguinte: Caso a largura da base do eletrodo tenha a mesma medida horizontal que o topo do eletrodo, este está corretamente alinhado. Caso a base seja menor, o eletrodo só pode estar mais distante do que o topo. Ou seja, está mais longe da câmera, o que significa que o eletrodo está em diagonal, com a ponta mais atrás do que o centro da tocha de soldagem. A mesma lógica aplica-se caso a base tenha uma medida maior que o topo, o que significa que o eletrodo está com a ponta à frente da tocha.

O programa em Matlab utilizou uma imagem definida como um padrão aceitável para calcular a matriz de transformação. Em seguida, o algoritmo passa a obter os valores à partir de imagens transformadas com esta matriz.

\section{Implementação do processamento em FPGA}

O algoritmo utilizado para implementação em Matlab foi adaptado para uma placa FPGA, utilizando-se a linguagem VHDL. Boa parte dos procedimentos continuou com a característica sequencial, pois as imagens são obtidas desta forma. Alguns procedimentos utilizaram do paralelismo para economia de tempo e recursos. Por exemplo: a obtenção de topo e base do arame e largura da poça de soldagem ocorrem simultaneamente. A seguir é demonstrado como foi feita a implementação de cada item do algoritmo.

\subsection{Aquisição de imagens}\label{section:desenv-aquisicao-imagens}
% falar da camera link na revisão bibliografica

Diferentemente do projeto em matlab, o algoritmo para a FPGA engloba captura de dados diretamente da câmera. Os dados fornecidos serialmente foram desserializados e disponibilizados em apenas um \textit{std\_logic\_vector} pois apenas eram necessários níveis de cinza.

A implementação em FPGA desenvolvida apenas recebe imagens para a função \textit{Freerunning Mode} da câmera. A princípio, o algoritmo não precisa de nenhum gatilho de sincronia enviado à câmera pois deve selecionar as imagens por conta própria como descrito em \ref{section:desenv-fpga-filtro_media_imagens}.

O primeiro passo para o recebimento do vídeo pela placa é a sincronização com o clock da câmera. Apesar deste clock ser fornecido pelo \textit{Channel Link}, as palavras de dados não são sincronizadas com a subida do clock. Também é necessario um sinal com 7 vezes a frequencia do clock fornecido para fazer a leitura dos 7 bits de cada palavra transmitida por ciclo. 

%\subsubsection{PLL}\label{section:PLL-desenv}
%
%Foi utilizado um PLL (\textit{Phase-locked loop}) para esta função, pois cria tanto o clock sincronizado com as palavras de dados quanto o clock para a leitura dos bits dessas palavras. O Quartus II permite a configuração de PLLs através do \textit{MegaWizard Plugin Manager} com o Plug-in chamado ''ALTPLL''.
%
%Foi utilizado um PLL com um sinal de entrada e dois de saída. O primeiro sinal de saída tem a mesma frequência do sinal de entrada e uma defasagem de 102º. Além disso foi configurado o \textit{duty cycle} deste sinal como 57\% para manter a mesma proporção de 4:3 do clock do \textit{Camera Link}. Este sinal foi automáticamente denominado $c0$ pelo \textit{MegaWizard Plugin Manager}.
%
%o segundo sinal de saída tem um fator de multiplicação de 7 e um fator de divisão de 2, sendo assim 3,5 vezes mais rápido que o primeiro sinal. Esta frequência foi escolhida dessa forma pois o módulo desserializador descrito em \ref{section:LVDS-desenv} aceita a sincronização tanto com subida quanto descida do sinal. Este sinal foi automáticamente denominado $c1$ pelo \textit{MegaWizard Plugin Manager}.
%
%Este módulo foi chamada simplesmente de ''PLL'' na configuração.
%
%\subsubsection{Desserializador LVDS}\label{section:LVDS-desenv}
%
%Os dados seriais são transformados em uma única palavra de 28 bits com ajuda do Plug-in ''ALTLVDS\_RX'' do Quartus II. Este módulo possui tem como entrada os quatro canais do \textit{Camera Link}, $c0$ e $c1$. O vetor de 28 bits que compõe a saída, foi denominado $rx\_out$ pelo \textit{MegaWizard Plugin Manager}. Infelizmente, os bits não saem deste módulo na ordem desejada, portanto foram necessários alguns roteamentos para separar os oito bits usados para processamento e os bits de validação.
%
%Este módulo foi configurado sem um PLL interno pois não seria possível satisfazer todas as especificações do protocolo, como o atraso de fase. Por esse motivo foi utilizado o PLL descrito em \ref{section:PLL-desenv}
%
%Este módulo foi chamada de ''deserializer'' na configuração.
%
%Por fim, os módulos ''PLL'' e ''deserializer'' foram instancializados em uma entidade chamada ''ReceptorDados'' que fornece os dados corretamente para o resto do sistema.


\subsection{Constantes e tipos customizados}

Para agilizar o desenvolvimento do projeto foi criada um pacote com valores e tipos que são recorrentemente utilizados nas diversas entidades. As constantes e tipos dependem basicamente das dimensões das imagens que se pretende processar. São estes:

\begin{enumerate}
\item Constantes
\begin{itemize}
\item $numcols$: Largura da imagem, ou quantidade de colunas (pixels) na dimensão horizontal;
\item $numlin$: Altura da imagem, ou quantidade de linhas (pixels) na dimensão vertical.
\end{itemize}
\item Tipos
\begin{itemize}
\item $vetorHor$: Vetor utilizado para guardar algum tipo de informação de cada linha. Possui $numlin$ elementos do tipo inteiro;
\item $vetorVert$: Vetor utilizado para guardar algum tipo de informação de cada coluna. Possui $numcols$ elementos do tipo inteiro;
\item $MatrizImagem$ Matriz utilizada para armazenar imagens inteiras na  simulação. Tem tamanho de $numlin$ por $numcols$ do tipo \textit{unsigned} de 8b.
\end{itemize}
\end{enumerate}

\subsection{Retirada de scanlines}

Assim que os dados estejam corretamente disponíveis para processamento começam a passar por etapas semelhantes às descritas na seção \ref{section:implementacao-matlab}. A primeira etapa é a retirada de \textit{scanlines}.

Este filtro de binarização é feito antes de qualquer outro, no momento de recepção de cada pixel. O código para tal é tão simples que foi deixado no corpo da entidade de projeto pois não justifica a criação de uma entidade para tal e não seria adequado colocá-lo em outra.

A binarização consiste basicamente transformar em zero qualquer pixel que seja maior que $threshold1$. O valor utilizado para testes $threshold1$ foi de 7, sendo o brilho máximo 255.

\subsection{Filtro de imagem média e seleção de imagens propícias} \label{section:desenv-fpga-filtro_media_imagens}

Para que fosse implementado este filtro foi utilizado um bloco de memória subdividido em quatro blocos, cada um dimensionado para receber uma imagem. A placa recebe sequencialmente os dados da câmera e armazena três imagens em memória. A imagem média não necessita ser armazenada pois cada pixel pode ser obtido através da média dos pixels das imagens armazenadas à medida que for necessário. 

A seleção de imagens propícias ao processamento foi feito no momento de obtenção da imagem. Uma nova imagem é armazenada no bloco marcado como $ bloco\_atual $. Ao final do recebimento desta, o sinal $ bloco\_atual $ permanece inalterado caso a imagem apresente brilho excessivo ou tem seu valor aumentado de 1 caso contrário. Se $ bloco\_atual $ permanece com o mesmo valor, a imagem recebida mais recentemente é sobrescrita pela nova imagem que será recebida em seguida. Se $ bloco\_atual $ for acrescido, então a imagem mais antiga é sobrescrita. Desta forma, à partir da terceira imagem sempre há três imagens úteis carregadas e uma sendo recebida.

\begin{figure}[h]
\subfigure[\label{fig:esquematico-memoria-1}]{
	\centering
	\includegraphics[width=\textwidth]{./Figuras/Esquematico-memoria-1.jpg}}
\subfigure[\label{fig:esquematico-memoria-2}]{
	\centering
	\includegraphics[width=\textwidth]{./Figuras/Esquematico-memoria-2.jpg}}
\subfigure[\label{fig:esquematico-memoria-3}]{
	\centering
	\includegraphics[width=\textwidth]{./Figuras/Esquematico-memoria-3.jpg}}
\caption{Funcionamento dos blocos de memória.}
\label{fig:esquematico-memoria}
\end{figure}


Para que isto fosse possível durante a simulação, foi implementado um bloco de RAM utilizando uma \textit{megafunction} do Quartus II. O tamanho desta memória calculado para armazenar quatro vezes a quantidade de bits de uma imagem. Para os primeiros estágios do desenvolvimento e teste, foram utilizadas imagens de 296x264 pixels reduzidas a 60x60 pixels (para economia de tempo e melhor visualização da simulação). O tamanho desta memória deveria comportar $ 60 \times 60 \times 4 = 1440 B $, portanto foi utilizada uma memória de 16 KB.

O interessante dessa implementação é que o endereçamento de leitura e escrita pode utilizar diretamente o sinal $ bloco\_atual $ com uma simples concatenação, o que poupa operações na implementação em VHDL e recursos na placa.

Como será visto mais detalhadamente abaixo em \ref{section:topo_base}, os cálculos e operações são feitos a cada novo pixel durante o carregamento de uma imagem. Assim, a média de cada pixel das últimas três imagens válidas deve ser calculada a cada ciclo de \textit{clock}. Como os valores absolutos não são de interesse durante os cálculos ficou decidido que a soma das três imagens seria suficiente, o que evita uma divisão desnecessária.

Durante a implementação foi constatado que fazer a leitura de diversos pixels em diferentes endereços de memória podeira consumir muito tempo e talvez se tornar proibitivo caso se deseje uma quantidade maior de imagens no filtro de média. A solução para este problema foi utilizar uma espécie de média móvel nos sinais que são utilizados para os cálculos. Em vez de se fazer a leitura de dois endereços de memória mais recentes para somá-los com o novo pixel recebido ($dado\_escrita$), foi feita apenas a leitura do mais antigo par ser subtraído da soma. Por exemplo: quando era feito o recebimento de um pixel da linha $linha$, coluna $coluna$ o valor do elemento $somaHor(linha)$ era atualizado da seguinte forma:

\begin{equation}
somaHor(linha) = somaHor(linha) + dado\_escrita - q(bloco\_atual - 3,linha,coluna)
\end{equation}

Onde $q$ é o byte armazenado no endereço de memória dado por $bloco\_atual$ concatenado com $linha \times numcols + coluna$,  sendo $numcols$ a largura da imagem.

\subsection{Cálculo de topo e base do arame} \label{section:topo_base}

Os dados de topo e base do arame foram obtidos com a mesma lógica criada para Matlab e de forma sequencial. Foi utilizado um processo que tem $in_janela$ e $in_clock$ como lista de sensitividade. O sinal $in_janela$ foi utilizado para sincronização de final de imagem e o $in_clock$ era o \textit{clock} de entrada da câmera e define o fim e o começo da transmissão de cada pixel.

Foram criados os mesmos vetores $somaHor$ e o $derivadaHor$ ambos do tipo $vetorHor$. Como citado em \ref{section:desenv-fpga-filtro_media_imagens} os elementos de $somaHor$ foram calculados a cada pixel recebido, mas os valores de $derivadaHor$ apenas foram calculados ao final da leitura de cada linha.

Ao mesmo tempo foram definidos os valores $posArameTopo$ e $posArameBase$ com simples testes ao final de cada linha. Ao final da imagem estes valores já estão devidamente definidos.

% apresentar resultados a cada imagem lida

\subsection{Laterais do Eletrodo}

As laterais do eletrodo são definidas em dois estágios diferentes. Primeiro os pontos prováveis destas laterais são encontrados, depois é calculada a equação de reta que descreve essas laterais. O cálculo desta equação de reta é descrita em \ref{section:desenv-fpga-regressao}






\subsubsection{Regressão linear} \label{section:desenv-fpga-regressao}

Esta regressão é feita de forma simplificada para poupar elementos utilizados na placa e diminuir o tempo de cálculo.
Para tanto foi decidido que seriam utilizados apenas uma quantidade limitada de pontos por reta no momento do desenvolvimento. Essa quantidade foi a princípio definida como $qtdPontosArame = 16$ para a simulação com imagens de 60x60 pixels. Este valor foi escolhido por ser uma potência de 2 e também por ter sido testado com o programa em Matlab, com resultados satisfatórios.

Esta forma de se calcular permite que seja utilizado o método descrito em \ref{section:regressao-fpga}. As constantes utilizadas para as multiplicações pelos somatórios são previamente calculadas no momento do desenvolvimento do código de acordo com as equações \ref{eq:const-reg-fpga-A}, e \ref{eq:const-reg-fpga-B}.

Como os valores destas constantes são quase sempre muito pequenos (da ordem de $10^{-4}$ para 16 pontos), esses valores foram multiplicados por potências de 2 para serem utilizados na multiplicação pelos somatórios. Essas potências de 2 equivalem a \textit{shifts} para a esquerda nas constantes. O resultado de cada uma passa posteriormente por um \textit{shift} para a direita equivalentes à potência pela qual foram multiplicadas as constantes.

Os valores calculados para as contantes para 16 pontos, com seus proporcionais utilizados na no código VHDL, e as quantidades de \textit{shifts} são descritos na tabela \ref{table:constantes-reg-16}. É importante notar que os valores inteiros foram todos calculados de forma a se obter a máxima precisão com 18 bits, pois os multiplicadores da placa utilizada são de 18x18 bits.

\begin{table}
\centering
\begin{tabular} {|c|c|c|c|}
\hline
\textbf{Descrição} & \textbf{Valor} & \textbf{Inteiro usado} & \textbf{Utilizada com fator}\\ \hline
constRegressao1 & 0,0029 & $0,0029 * 2^{26}$ & a \\ \hline
constRegressao2 & 0,0221 & $0,0221 * 2^{23}$ & a,b \\ \hline
constRegressao3 & 0,2279 & $0,2279 * 2^{20}$ & b \\ \hline
\end{tabular}
\caption{Constantes utilizadas em regressão com 16 pontos}
\label{table:constantes-reg-16}
\end{table}


Os somatórios são calculados com os valores dos vetores $inicioArame$ e $fimArame$ entre os índices $posArameTopo$ e $posArameBase$. Assim como no algoritmo para Matlab, aqui também foi utilizado um afastamento entre o topo e a base para se evitar os cantos onde podem haver inconsistências. Este foi definido inicialmente como $afastamento = 2$ para a imagem de 60x60 pixels.

Para a definição dos índices nos vetores $inicioArame$ e $fimArame$ que seriam utilizados para a leitura dos valores foi feito um processo semelhante ao utilizado com as multiplicações de constantes acima. Isto foi necessário pois o para se utilizar uma quantidade limitada de pontos distribuídos o mais homogeneamente possível entre dois limites, sem a utilização de pontos flutuantes. Para melhor demostrar o problema: Imagine que se deseja 16 índices inteiros distribuídos entre os valores 14 e 42 de forma mais homogênea possível com ferramentas que não permitem o uso de números fracionários.

A solução encontra-se em utilizar valores inteiros e \textit{shifts}. Neste caso específico as variáveis de entrada, $posArameTopo$, $posArameBase$, $qtdPontosArame$ e $afastamento$ são todas inteiras. O que se necessita para a obtenção do n-ésimo índice pode ser melhor entendido com a equação \ref{eq:indice}.

\begin{align}
indice = i + (n - 1) \times \frac{intervalo}{qtdPontosArame}
\label{eq:indice}
\end{align}

Onde $i$ é o primeiro índice da série, $n$ se refere ao n-ésimo ponto e $intervalo/qtdPontosArame$ é a diferença entre dois pontos subsequentes que se deseja na série,  sendo $intervalo$ calculado acordo com a equação \ref{eq:intervalo}.

\begin{align}
\centering
intervalo = posArameBase - posArameTopo - afastamento - afastamento
\label{eq:intervalo}
\end{align}


O valor de $intervalo$ precisa ser sempre inteiro para se obter um índice válido no vetor. Caso a divisão ocorra antes da multiplicação, o valor truncado perde precisão. Por este motivo a equação \ref{eq:indice} foi adaptada na equação \ref{eq:indice-inteiro} para manter o melhor inteiro possível.

\begin{align}
\centering
indice = i + [(n - 1) \times intervalo] >> log_2(qtdePontosArame)
\label{eq:indice-inteiro}
\end{align}

O operador $>>$ denota a operação de \textit{shift}. Neste caso, serão feitos 4 \textit{shifts}, o que equivale a uma divisão por 16. O resultado final pode ser normalmente somado e multiplicado por ferramentas comuns da FPGA.

Os coeficientes obtidos com o cálculo simplificado devem ser corrigidos pois até este ponto as observações são consideradas como tendo avanço unitário no eixo X, e não aquelas calculadas por $intervalo/qtdPontosArame$.

%encontrar b com equação logo depois de {eq:sistema-linear-regressao} na revisão


%\subsection{Identificação do ângulo da câmera e distorção de perspectiva}

\section{Simulações}
% colocar nos resultados?

A maior parte do projeto foi desenvolvida sem a utilização de placas FPGA e câmeras reais, portanto foi essencial o uso de simulações. Cada criação ou alteração de código foi testada com auxílio das simulações a fim de evitar excessivo retrabalho em correções de erros.

O desenvolvimento em Matlab, utilizou arquivos de imagens como entrada, pois o \textit{software} tem diversas funções que facilitam a leitura de arquivos. A implementação em FPGA, por sua vez é bem mais complexa e utilizou o \textit{software} externo Modelsim com arquivos de texto como entrada.


\subsection{Simulações em Matlab}

A simulação em Matlab ocorre de forma bastante simples: basta rodar o programa gerado. Foi possível aproveitar das facilidades do software para imprimir as imagens de entrada processadas, ou seja, após a passagem dos filtros e com os valores calculados representados graficamente.

Os programas desenvolvidos em Matlab utilizaram de imagens previamente obtidas em outro trabalho \cite{luciano}. A câmera utilizada foi uma DALSA citada em \ref{section:rev-aquisicao-imagens} e foi montada conforme a figura \ref{fig:posicao-camera-luciano}.

O experimento utilizou um eletrodo de $r_{eletrodo} = 1mm$ de diâmetro, com $standoff = 15mm$. Parte do eletrodo fica coberta pelo bocal na captura das imagens, mas sabe-se que a câmera estava posicionada a $\alpha = 30^\circ$ em relação ao plano horizontal. Considerando o bocal da tocha de soldagem com \textbf{$ r_{bocal} = 10mm$} de diâmetro, a altura da $h$ parte visível do eletrodo é dada por:

\begin{align}
h = standoff - (r_{bocal} - r_{eletrodo}) \cdot sen(\alpha) \\
h = 15 - (10-0,5) \cdot sen(30) = 10,25mm
\end{align}

Os valores de $r_{eletrodo}$ e  $h$ foram utilizados para calcular a distorção de perspectiva à partir das próprias imagens. Apesar de essa não ser a opção desejada (o ideal seria uma calibração em separado) é suficiente para o propósito de simulação.






\subsection{Simulações em FPGA}

Inicialmente, o algoritmo foi desenvolvido como se os dados de entrada (pixels) e clock viessem de alguma forma já desserializados para a placa. Ou seja, havia apenas a entrada de um clock e um byte, além dos outros sinais de configuração. As entidades de processamento foram todas feitas de forma a receber informações desta forma genérica, o que se mostrou eficiente após serem criados os blocos descritos em \ref{section:desenv-aquisicao-imagens}.

Dessa forma foram utilizadas imagens previamente capturadas no trabalho de \cite{luciano}, da mesma forma que as simulações em Matlab. Porém, as imagens foram transformadas em blocos de texto para poderem ser usadas em um arquivo \textit{testbench}. 

\subsubsection{Conversão de Imagens para Simulação}
Este processo foi feito com a ajuda de um programa bastante simples disponível em distribuições Linux, chamado ''od''. Este programa traduz qualquer tipo de arquivo, inclusive imagens, para códigos hexadecimais. Um pequeno script foi criado para facilitar a utilização do programa. O resultado é um arquivo com palavras hexadecimais separadas por espaços, com a mesma quantidade de linhas e colunas que a imagem fornecida.

O texto deste arquivo é então inserido no arquivo de \textit{testbench} a ser carregado pelo Modelsim. Abaixo segue um trecho de imagem em formato de texto hexadecimal.

\begin{center}
\begin{tabular}{c c c c c c c c c}
03 & 03 & 03 & 07 & 07 & 07 & 31 & 31 & 31 \\
04 & 04 & 04 & 1c & 1c & 1c & 5b & 5b & 5b \\
0b & 0b & 0b & 49 & 49 & 49 & 7d & 7d & 7d \\
26 & 26 & 26 & 7f & 7f & 7f & 89 & 89 & 89 \\
47 & 47 & 47 & 93 & 93 & 93 & 6c & 6c & 6c \\
\end{tabular}
\end{center}

Note que em cada linha os valores são repetidos três a três. Isso acontece pois as imagens estavam armazenadas em arquivos do tipo \textit{bitmab} de três cores RGB, apesar de serem imagens em escala de cinza. Ou seja, cada um dos três valores repetidos representa uma cor de vermelho, verde ou azul. Apenas retirando dois de cada três desses valores tem-se o desejado. Esta etapa é facilmente feita com o uso de uma expressão regular, ou \textit{Regex}.

O resultado final dentro do \textit{testbench} é uma matriz com os valores desejados. Esses valores podem ser lidos por indexação de linha e coluna. Abaixo, segue o exemplo do começo, meio e final de uma dessas matrizes:

\begin{lstlisting}[language=VHDL]
CONSTANT imagem_teste0 : MatrizImagem :=
\end{lstlisting}

\begin{center}
\begin{tabular}{c c c c c c c c c}
(( X"03", & X"02", & X"03", ... & X"03", & X"02", & X"03", ... & X"02", & X"03", & X"03"), \\
 ( X"03", & X"02", & X"03", ... & X"da", & X"f5", & X"fe", ... & X"09", & X"03", & X"03"), \\
 ( X"03", & X"02", & X"03", ... & X"03", & X"02", & X"03", ... & X"02", & X"03", & X"03")); \\
\end{tabular}
\end{center}

\subsubsection{Sincronização}

A primeira versão do \textit{testbench} foi feita de forma a fornecer os pixels sequencialmente, sem um sinal de início de imagem ou de linhas. Isso obrigava os blocos que funcionavam em paralelo a fazer uma contagem para saber quando uma imagem ou linhas acabavam ou iniciavam. Cada entidade possuía um valor de $linha$ e um de $coluna$ para fazer essa contagem. Essa redundância gerava um custo desnecessário de recursos.

Logo chegou-se a conclusão que essa abordagem se tornaria um problema no caso real onde se deseja processar durante a captura de imagens. Então foram implementados os sinais $FVAL$ e $LVAL$ do padrão \textit{Camera Link} para simular a sincronia da captura e também evitar problemas futuros. 






